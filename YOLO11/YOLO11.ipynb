{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330b0cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Imports and global paths\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "from ultralytics import YOLO\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# %% Paths and basic settings\n",
    "\n",
    "# IMPORTANT:\n",
    "# Open this notebook inside the YOLO11 folder (where YOLO11.ipynb lives),\n",
    "# so that Path.cwd() == .../YOLO11\n",
    "ROOT_DIR = Path.cwd()\n",
    "\n",
    "# Dataset root and data.yaml path\n",
    "DATA_ROOT = Path(r\"E:\\2025 fall\\Fundamentals of Digital Image Processing\")\n",
    "DATA_YAML = DATA_ROOT / \"data.yaml\"\n",
    "\n",
    "# Name of the training run (folder under ROOT_DIR)\n",
    "RUN_NAME = \"results\"     \n",
    "RUN_DIR = ROOT_DIR / RUN_NAME\n",
    "RUN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Finetune dataset root & yaml\n",
    "FT_DATA_ROOT = Path(r\"E:\\2025 fall\\Fundamentals of Digital Image Processing\\Low Resolution_fine tune\")\n",
    "FT_DATA_YAML = DATA_ROOT / \"data_finetune.yaml\"\n",
    "\n",
    "# Finetune run name\n",
    "FT_RUN_NAME = \"finetune_motion blur\"\n",
    "FT_RUN_DIR = ROOT_DIR / FT_RUN_NAME\n",
    "\n",
    "print(\"ROOT_DIR :\", ROOT_DIR)\n",
    "print(\"DATA_YAML:\", DATA_YAML)\n",
    "print(\"RUN_DIR  :\", RUN_DIR)\n",
    "print(\"Fine-Tune_YAML:\", FT_DATA_YAML)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ee4c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Helper functions: path resolving and train subsampling\n",
    "\n",
    "def resolve_path(base: Path, p: str) -> Path:\n",
    "    \"\"\"Turn a path from data.yaml into an absolute path.\"\"\"\n",
    "    p_path = Path(p)\n",
    "    if p_path.is_absolute():\n",
    "        return p_path\n",
    "    return (base / p_path).resolve()\n",
    "\n",
    "\n",
    "def fix_split_path(cfg: dict, base_dir: Path, key: str) -> Optional[Path]:\n",
    "    \"\"\"\n",
    "    Fix cfg[key] (train/val/test) to a valid absolute path.\n",
    "\n",
    "    Priority:\n",
    "        1. Use the path in data.yaml if it exists.\n",
    "        2. Try base_dir/<key>/images.\n",
    "        3. Try base_dir/<key>.\n",
    "    \"\"\"\n",
    "    if key not in cfg:\n",
    "        return None\n",
    "\n",
    "    raw = cfg[key]\n",
    "    path = resolve_path(base_dir, raw)\n",
    "    if path.exists():\n",
    "        cfg[key] = str(path)\n",
    "        print(f\"[INFO] Using {key} path from yaml: {path}\")\n",
    "        return path\n",
    "\n",
    "    cand = base_dir / key / \"images\"\n",
    "    if cand.exists():\n",
    "        cfg[key] = str(cand)\n",
    "        print(f\"[WARN] {key} path {path} not found, using fallback {cand}\")\n",
    "        return cand\n",
    "\n",
    "    cand2 = base_dir / key\n",
    "    if cand2.exists():\n",
    "        cfg[key] = str(cand2)\n",
    "        print(f\"[WARN] {key} path {path} not found, using fallback {cand2}\")\n",
    "        return cand2\n",
    "\n",
    "    print(f\"[ERROR] Could not resolve path for {key}: {raw}\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def create_subsampled_train(\n",
    "    data_yaml: Path,\n",
    "    max_train_images: int = 3000,\n",
    "    seed: int = 42,\n",
    ") -> Path:\n",
    "    \"\"\"\n",
    "    Read the original data.yaml, fix train/val/test paths,\n",
    "    create a subsampled train set under DATA_ROOT/train_small,\n",
    "    and write a new data_subsampled.yaml next to data.yaml.\n",
    "\n",
    "    Rules:\n",
    "        - Only sample once: if train_small/images is non-empty, reuse it.\n",
    "        - Sort file names + use a fixed random seed -> deterministic subset.\n",
    "        - For each selected image, copy the matching .txt label.\n",
    "    \"\"\"\n",
    "    data_yaml_path = Path(data_yaml)\n",
    "    with data_yaml_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        cfg = yaml.safe_load(f)\n",
    "\n",
    "    base_dir = data_yaml_path.parent\n",
    "\n",
    "    # Fix paths for all splits\n",
    "    train_path = fix_split_path(cfg, base_dir, \"train\")\n",
    "    val_path = fix_split_path(cfg, base_dir, \"val\")\n",
    "    _ = fix_split_path(cfg, base_dir, \"test\")  # keep test for later evaluation\n",
    "\n",
    "    if train_path is None:\n",
    "        raise RuntimeError(\"Could not resolve a valid train path from data.yaml\")\n",
    "\n",
    "    # Assume train_path points to an images folder\n",
    "    train_images_dir = Path(train_path)\n",
    "    if train_images_dir.name.lower() != \"images\":\n",
    "        cand = train_images_dir / \"images\"\n",
    "        if cand.exists():\n",
    "            train_images_dir = cand\n",
    "\n",
    "    train_labels_dir = train_images_dir.parent / \"labels\"\n",
    "\n",
    "    # Subset folders: DATA_ROOT/train_small/images, .../labels\n",
    "    subset_root = base_dir / \"train_small\"\n",
    "    subset_images_dir = subset_root / \"images\"\n",
    "    subset_labels_dir = subset_root / \"labels\"\n",
    "    subset_images_dir.mkdir(parents=True, exist_ok=True)\n",
    "    subset_labels_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    existing_imgs = list(subset_images_dir.glob(\"*.*\"))\n",
    "    if existing_imgs:\n",
    "        print(\n",
    "            f\"[INFO] Subsampled train already exists at {subset_images_dir} \"\n",
    "            f\"with {len(existing_imgs)} images. Reusing it.\"\n",
    "        )\n",
    "    else:\n",
    "        all_imgs = [\n",
    "            p for p in train_images_dir.iterdir()\n",
    "            if p.is_file() and p.suffix.lower() in {\".jpg\", \".jpeg\", \".png\", \".bmp\"}\n",
    "        ]\n",
    "        all_imgs = sorted(all_imgs, key=lambda x: x.name)\n",
    "        n_total = len(all_imgs)\n",
    "        if n_total == 0:\n",
    "            raise RuntimeError(f\"No images found in {train_images_dir}\")\n",
    "\n",
    "        n_select = min(max_train_images, n_total)\n",
    "        print(f\"[INFO] Found {n_total} train images, sampling {n_select} for subset.\")\n",
    "\n",
    "        rng = random.Random(seed)\n",
    "        selected = rng.sample(all_imgs, n_select)\n",
    "\n",
    "        for img_path in selected:\n",
    "            dst_img = subset_images_dir / img_path.name\n",
    "            shutil.copy2(img_path, dst_img)\n",
    "\n",
    "            label_src = train_labels_dir / f\"{img_path.stem}.txt\"\n",
    "            if label_src.exists():\n",
    "                dst_label = subset_labels_dir / label_src.name\n",
    "                shutil.copy2(label_src, dst_label)\n",
    "            else:\n",
    "                print(f\"[WARN] Label not found for {img_path.name}, skipping label.\")\n",
    "\n",
    "        print(\n",
    "            f\"[INFO] Subsampled train created at {subset_images_dir} \"\n",
    "            f\"with {len(selected)} images.\"\n",
    "        )\n",
    "\n",
    "    # Build new yaml config\n",
    "    new_cfg = dict(cfg)\n",
    "    new_cfg[\"train\"] = str(subset_images_dir)\n",
    "    if val_path is not None:\n",
    "        new_cfg[\"val\"] = str(Path(new_cfg[\"val\"]))\n",
    "    # \"test\" was already fixed by fix_split_path, so we keep it as is.\n",
    "\n",
    "    new_yaml_path = data_yaml_path.with_name(\"data_subsampled.yaml\")\n",
    "    with new_yaml_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        yaml.safe_dump(new_cfg, f, sort_keys=False, allow_unicode=True)\n",
    "\n",
    "    print(f\"[INFO] New data yaml written to {new_yaml_path}\")\n",
    "    return new_yaml_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87756ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Training (set DO_TRAIN = False if you only want to reuse existing results)\n",
    "\n",
    "DO_TRAIN = False   # change to True if you want to train again\n",
    "\n",
    "EPOCHS = 100\n",
    "IMGSZ = 640\n",
    "BATCH = 16\n",
    "MODEL_NAME = \"yolo11n.pt\" # select model version\n",
    "\n",
    "if DO_TRAIN:\n",
    "    subsampled_yaml = create_subsampled_train(\n",
    "        data_yaml=DATA_YAML,\n",
    "        max_train_images=3000,\n",
    "        seed=42,\n",
    "    )\n",
    "\n",
    "    model = YOLO(MODEL_NAME)\n",
    "\n",
    "    model.train(\n",
    "        data=str(subsampled_yaml),\n",
    "        epochs=EPOCHS,\n",
    "        imgsz=IMGSZ,\n",
    "        batch=BATCH,\n",
    "        workers=2,           \n",
    "        project=str(ROOT_DIR),\n",
    "        name=RUN_NAME,       \n",
    "        exist_ok=True,\n",
    "        plots=False,          \n",
    "    )\n",
    "else:\n",
    "    print(\"Skipping training, reusing existing run:\", RUN_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01ed62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Finetune YOLO11\n",
    "from ultralytics import YOLO\n",
    "\n",
    "DO_FINETUNE = True\n",
    "\n",
    "FT_EPOCHS = 40\n",
    "FT_IMGSZ = 640\n",
    "FT_BATCH = 16\n",
    "\n",
    "\n",
    "if DO_FINETUNE:\n",
    "\n",
    "    base_weights = ROOT_DIR / \"results\" / \"weights\" / \"best.pt\"\n",
    "\n",
    "    print(\"Finetune base weights:\", base_weights)\n",
    "    model_ft = YOLO(str(base_weights))\n",
    "\n",
    "    \n",
    "    model_ft.train(\n",
    "        data=str(FT_DATA_YAML),\n",
    "        epochs=FT_EPOCHS,\n",
    "        imgsz=FT_IMGSZ,\n",
    "        batch=FT_BATCH,\n",
    "        workers=2,\n",
    "        project=str(ROOT_DIR),\n",
    "        name=FT_RUN_NAME,     \n",
    "        exist_ok=True,\n",
    "        plots=False,          \n",
    "    )\n",
    "else:\n",
    "    print(\"Skipping finetune training, reusing existing run:\", FT_RUN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5325b4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Load best model from the training run\n",
    "\n",
    "BEST_WEIGHTS = RUN_DIR / \"weights\" / \"best.pt\"\n",
    "assert BEST_WEIGHTS.exists(), f\"best.pt not found at {BEST_WEIGHTS}\"\n",
    "\n",
    "best_model = YOLO(str(BEST_WEIGHTS))\n",
    "print(\"Loaded model from:\", BEST_WEIGHTS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fcb629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Load best model from the fine-tuning run\n",
    "FT_BEST_WEIGHTS = FT_RUN_DIR / \"weights\" / \"best.pt\"\n",
    "assert FT_BEST_WEIGHTS.exists(), f\"Finetune best.pt not found at {FT_BEST_WEIGHTS}\"\n",
    "best_model_ft = YOLO(str(FT_BEST_WEIGHTS))\n",
    "print(\"Loaded finetuned weights from:\", FT_BEST_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3cda9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Evaluate on validation set (with plots)\n",
    "\n",
    "metrics_val = best_model.val(\n",
    "    data=str(DATA_ROOT / \"data_subsampled.yaml\"),  # or DATA_YAML if you prefer full train\n",
    "    split=\"val\",\n",
    "    workers=2,\n",
    "    plots=True,   # keep the YOLO-generated plots and val_batch* images\n",
    ")\n",
    "\n",
    "box_val = metrics_val.box\n",
    "\n",
    "map_5095_val = float(box_val.map)       # mAP@[.5:.95]\n",
    "map_50_val   = float(box_val.map50)     # mAP@0.5\n",
    "map_75_val   = float(box_val.map75)     # mAP@0.75\n",
    "\n",
    "# mean precision/recall/F1 over classes\n",
    "mp_val  = float(box_val.mp)\n",
    "mr_val  = float(box_val.mr)\n",
    "mf1_val = float(box_val.f1.mean())  # .f1 is per-confidence; we take mean as a summary\n",
    "\n",
    "print(\"\\n=== Validation metrics (boxes, B) ===\")\n",
    "print(f\"AP@[.5:.95](B): {map_5095_val:.4f}\")\n",
    "print(f\"AP@0.5(B)    : {map_50_val:.4f}\")\n",
    "print(f\"AP@0.75(B)   : {map_75_val:.4f}\")\n",
    "print(f\"mean P(B)     : {mp_val:.4f}\")\n",
    "print(f\"mean R(B)     : {mr_val:.4f}\")\n",
    "print(f\"mean F1(B)    : {mf1_val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fbf834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Evaluate on TEST set (no plots, just numbers) + save to runs\n",
    "\n",
    "metrics_test = best_model.val(\n",
    "    data=str(DATA_ROOT / \"data_subsampled.yaml\"),\n",
    "    split=\"test\",    # this uses the \"test\" path from data_subsampled.yaml\n",
    "    workers=2,\n",
    "    plots=False,     # do not generate extra curves/images for test\n",
    ")\n",
    "\n",
    "box_test = metrics_test.box\n",
    "\n",
    "map_5095_test = float(box_test.map)\n",
    "map_50_test   = float(box_test.map50)\n",
    "map_75_test   = float(box_test.map75)\n",
    "mp_test       = float(box_test.mp)\n",
    "mr_test       = float(box_test.mr)\n",
    "mf1_test      = float(box_test.f1.mean())\n",
    "\n",
    "print(\"\\n=== TEST metrics (boxes, B) ===\")\n",
    "print(f\"AP@[.5:.95](B): {map_5095_test:.4f}\")\n",
    "print(f\"AP@0.5(B)    : {map_50_test:.4f}\")\n",
    "print(f\"AP@0.75(B)   : {map_75_test:.4f}\")\n",
    "print(f\"mean P(B)     : {mp_test:.4f}\")\n",
    "print(f\"mean R(B)     : {mr_test:.4f}\")\n",
    "print(f\"mean F1(B)    : {mf1_test:.4f}\")\n",
    "\n",
    "# ---- Save test metrics under runs/ with a folder name indicating TEST ----\n",
    "# Folder: ROOT_DIR / \"runs\" / \"test_metrics\"\n",
    "test_results_dir = ROOT_DIR / \"runs\" / \"test_metrics\"\n",
    "test_results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save as a readable text file\n",
    "txt_path = test_results_dir / \"metrics_test_Low Resolution_fine tune_traditional.txt\"\n",
    "with txt_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"=== TEST metrics (boxes, B) ===\\n\")\n",
    "    f.write(f\"AP@[.5:.95](B): {map_5095_test:.6f}\\n\")\n",
    "    f.write(f\"AP@0.5(B)    : {map_50_test:.6f}\\n\")\n",
    "    f.write(f\"AP@0.75(B)   : {map_75_test:.6f}\\n\")\n",
    "    f.write(f\"mean P(B)     : {mp_test:.6f}\\n\")\n",
    "    f.write(f\"mean R(B)     : {mr_test:.6f}\\n\")\n",
    "    f.write(f\"mean F1(B)    : {mf1_test:.6f}\\n\")\n",
    "\n",
    "print(f\"\\n[Test metrics saved to]\")\n",
    "print(f\"  {txt_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b1068f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Evaluate finetuned model on TEST set \n",
    "# remember to change the path in data_finetune.yaml to the needed one\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "TEST_METRICS_DIR = ROOT_DIR / \"runs\" / \"test_metrics\"\n",
    "TEST_METRICS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "metrics_test_ft = best_model_ft.val(\n",
    "    data=str(FT_DATA_YAML),\n",
    "    split=\"test\",    \n",
    "    workers=2,\n",
    "    plots=False,     \n",
    ")\n",
    "\n",
    "box_test = metrics_test_ft.box\n",
    "map_5095_test = float(box_test.map)\n",
    "map_50_test   = float(box_test.map50)\n",
    "map_75_test   = float(box_test.map75)\n",
    "mp_test       = float(box_test.mp)\n",
    "mr_test       = float(box_test.mr)\n",
    "mf1_test      = float(box_test.f1.mean())\n",
    "\n",
    "print(\"\\n=== Finetune TEST metrics (boxes, B) ===\")\n",
    "print(f\"mAP@[.5:.95](B): {map_5095_test:.4f}\")\n",
    "print(f\"mAP@0.5(B)    : {map_50_test:.4f}\")\n",
    "print(f\"mAP@0.75(B)   : {map_75_test:.4f}\")\n",
    "print(f\"mean P(B)     : {mp_test:.4f}\")\n",
    "print(f\"mean R(B)     : {mr_test:.4f}\")\n",
    "print(f\"mean F1(B)    : {mf1_test:.4f}\")\n",
    "\n",
    "txt_path_ft = TEST_METRICS_DIR / \"metrics_test_motion blur_finetune.txt\"\n",
    "with txt_path_ft.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"=== Finetune TEST metrics (boxes, B) ===\\n\")\n",
    "    f.write(f\"mAP@[.5:.95](B): {map_5095_test:.6f}\\n\")\n",
    "    f.write(f\"mAP@0.5(B)    : {map_50_test:.6f}\\n\")\n",
    "    f.write(f\"mAP@0.75(B)   : {map_75_test:.6f}\\n\")\n",
    "    f.write(f\"mean P(B)     : {mp_test:.6f}\\n\")\n",
    "    f.write(f\"mean R(B)     : {mr_test:.6f}\\n\")\n",
    "    f.write(f\"mean F1(B)    : {mf1_test:.6f}\\n\")\n",
    "\n",
    "print(\"\\n[Finetune test metrics saved to]\")\n",
    "print(\" \", txt_path_ft)\n",
    "\n",
    "test_images_dir = FT_DATA_ROOT / \"images\" / \"test\"\n",
    "assert test_images_dir.exists(), f\"Test images dir not found: {test_images_dir}\"\n",
    "\n",
    "pred_results_ft = best_model_ft.predict(\n",
    "    source=str(test_images_dir),\n",
    "    imgsz=FT_IMGSZ,\n",
    "    conf=0.25,   \n",
    "    iou=0.5,\n",
    "    project=str(ROOT_DIR / \"runs\" / \"detect\"),\n",
    "    name=\"test_motion blur_finetune\",   \n",
    "    save=True,\n",
    ")\n",
    "\n",
    "print(\"\\n Finetune test predictions saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f848380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Plot training/validation loss curves from results.csv\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "RESULTS_CSV = DATA_ROOT/ \"YOLO11\" /\"finetune_low resolution\" / \"results.csv\" # change the path according to the needs\n",
    "assert RESULTS_CSV.exists(), f\"results.csv not found at {RESULTS_CSV}\"\n",
    "\n",
    "df = pd.read_csv(RESULTS_CSV)\n",
    "print(\"Columns in results.csv:\\n\", df.columns, \"\\n\")\n",
    "\n",
    "# ---- Loss curves ----\n",
    "metrics_loss = [\n",
    "    (\"train/box_loss\", \"train/box_loss\"),\n",
    "    (\"train/cls_loss\", \"train/cls_loss\"),\n",
    "    (\"train/dfl_loss\", \"train/dfl_loss\"),\n",
    "    (\"val/box_loss\",   \"val/box_loss\"),\n",
    "    (\"val/cls_loss\",   \"val/cls_loss\"),\n",
    "    (\"val/dfl_loss\",   \"val/dfl_loss\"),\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(14, 8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "epochs = df.index + 1  # x-axis\n",
    "\n",
    "for ax, (col, title) in zip(axes, metrics_loss):\n",
    "    ax.plot(epochs, df[col])\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"epoch\")\n",
    "    ax.set_ylabel(\"loss\")\n",
    "    ax.grid(True, linestyle=\"--\", alpha=0.4)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# save + show\n",
    "loss_fig_path = DATA_ROOT/ \"YOLO11\" /\"finetune_low resolution\" / \"loss curves_finetune_low resolution.png\" # change the path according to the needs\n",
    "fig.savefig(loss_fig_path, dpi=300)\n",
    "print(f\"Loss curves saved to: {loss_fig_path}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a319242e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Plot precision / recall / mAP vs epoch from results.csv\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
    "\n",
    "epochs = df.index + 1\n",
    "\n",
    "# precision(B)\n",
    "axes[0].plot(epochs, df[\"metrics/precision(B)\"])\n",
    "axes[0].set_title(\"precision(B)\")\n",
    "axes[0].set_xlabel(\"epoch\")\n",
    "axes[0].set_ylabel(\"precision\")\n",
    "axes[0].set_ylim(0, 1)\n",
    "axes[0].grid(True, linestyle=\"--\", alpha=0.4)\n",
    "\n",
    "# recall(B)\n",
    "axes[1].plot(epochs, df[\"metrics/recall(B)\"])\n",
    "axes[1].set_title(\"recall(B)\")\n",
    "axes[1].set_xlabel(\"epoch\")\n",
    "axes[1].set_ylabel(\"recall\")\n",
    "axes[1].set_ylim(0, 1)\n",
    "axes[1].grid(True, linestyle=\"--\", alpha=0.4)\n",
    "\n",
    "# mAP50 & mAP50-95\n",
    "axes[2].plot(epochs, df[\"metrics/mAP50(B)\"], label=\"AP50\")\n",
    "axes[2].plot(epochs, df[\"metrics/mAP50-95(B)\"], label=\"AP50-95\")\n",
    "axes[2].set_title(\"AP50 / AP50-95\")\n",
    "axes[2].set_xlabel(\"epoch\")\n",
    "axes[2].set_ylabel(\"AP\")\n",
    "axes[2].set_ylim(0, 1)\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, linestyle=\"--\", alpha=0.4)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "metrics_fig_path = DATA_ROOT/ \"YOLO11\" /\"finetune_low resolution\" / \"training curves_finetune_low resolution.png\" # change the path according to the needs\n",
    "fig.savefig(metrics_fig_path, dpi=300)\n",
    "print(f\"Training metrics curves saved to: {metrics_fig_path}\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
